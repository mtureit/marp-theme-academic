AI-native Memory 2.0: Second Me

Jiale Wei, Xiang Ying, Tao Gao, Fangyi Bao, Felix Tao, Jingbo Shang

Mindverse.ai

{yingxiang, tao}@mindverse.ai

1/16

概要

Abstract

人間と外部世界とのインタラクションは、個人の記憶の交換に基づいて
いる

既存のソリューション（ブラウザ認証情報、自動入力機能など）は静的
な記憶のリポジトリとして機能

大規模言語モデル（LLM）はSECOND MEという新しいAIネイティブな
パラダイムを可能にする

SECOND MEは知的で永続的なメモリオフロードシステムとして機能

ユーザー固有の知識を保持、整理し、動的に活用

LLMベースのメモリパラメータ化により構造化された組織、文脈的推
論、適応的知識検索を実現

2/16

導入

Introduction

人間の外部世界とのインタラクションは記憶に大きく依存している

繰り返し個人データを提供する冗長性は認知的疲労を引き起こす

既存のソリューションは静的リポジトリとして機能

LLMは記憶管理をAIネイティブなアプローチで再定義する機会を提供

center

3/16

SECOND MEの概要

SECOND MEの全体設計

center

注: 本来はFigure 1: Hybrid Architecture of SECOND MEの図が入ります

4/16

SECOND MEの概要

Large Personal Model (LPM) 1.0の復習

LPM 1.0では、メモリは3つの層に分類される：

L0: 生データ層 - 非構造化データ全体

L1: 自然言語メモリ層 - ユーザーの簡潔なバイオグラフィ、重要な文や
語句のリスト、選好タグなど

L2: AIネイティブメモリ層 - 必ずしも自然言語による記述を必要としな
い、モデルパラメータを通じて学習‧整理される記憶

SECOND MEはこの3層アーキテクチャを継承し、さらに強化

5/16

SECOND MEの概要

SECOND MEの新機能

LPM 1.0からのアップグレード：

強化された層の統合: LPM 1.0では層が独立して機能していたが、
SECOND MEではL0とL1がL2により豊かな文脈サポートを提供

L2の役割の再定義: L2は複雑なユーザーニーズに対応するために外部の
専門モデルを活用するオーケストレーターとして機能

自動化されたトレーニングパイプライン: データ合成、フィルタリン
グ、SFT、DPO、評価を含む完全に自動化されたパイプラインを確立

6/16

実践と結果

トレーニングの概要

トレーニングの目的:

単純なタスクではユーザーを直接支援

複雑な問題では汎用LLMと協力

ユーザーのコンテキストを常に維持

3つの主要なデプロイメントシナリオ:

1. Memory QA: 知識検索、概念理解、行動予測、アイテム推奨

2. Context Enhancement: ユーザーがエキスパートモデルにクエリを行

う際、関連する詳細情報を強化

3. Context Critic: 外部エージェントとのインタラクション中にユーザー

7/16

実践と結果

トレーニングパイプライン

center

注: 本来はFigure 2: Automated Personal Model pipeline with LLM as a Judge and LLM

as data synthesizerの図が入ります

完全自動化されたパイプライン:

1. 生データ

2. データマイニング（エンティティ、トピック、関連情報の抽出）

3. メモリデータの合成

4. コンテキスト強化とコンテキスト批評データの生成

5. 5段階のフィルタリングプロセス

8/16

実践と結果

回答スタイル: CoT（思考連鎖）の活用

Chain-of-Thought (CoT) データを生成するための戦略:

Weak: 専門家モデルがCoTパターンで応答、形式や内容の制約なし

Multi-step: 最初の推論ステップで推論プロセスのみを生成、次のステ
ップで最終回答を生成

Strong: Deepseek-R1を専門家モデルとして使用、詳細なCoT推論と回
答を厳格な形式制約と長さ制限で生成

9/16

実践と結果

トレーニング戦略: DPO（Direct Preference Optimization）

SFTとは異なり、DPOアプローチは訓練済みモデルに追加の知識を導入
しない

代わりに、ユーザーのアップロードデータを活用してユーザー選好の理解を高める

重要なエンティティと関係に焦点を当てる

選好ペアは全SFTトレーニングデータの約20%を構成

より個人化された効率的なトレーニングプロセスを実現

10/16

実践と結果

評価設定と結果

評価指標:

Memory (Self): 第一人称でのL2との対話

Memory (Third-party): 第三者としてのL2との対話

Context Enhance: L2によるコンテキスト強化の質

Context Critic: L2によるコンテキスト批評の質

主な結果:

Strong CoTがモデルのパフォーマンスを大幅に向上

DPOは全タスクで一貫したパフォーマンス向上をもたらす

11/16

人間による評価ではLLMベースの評価よりも高いスコアを示す傾向があ

実践と結果

実験結果

COTレベルによる結果の比較:

COT

Strong

Multi-
step

Weak

Memory
(Self)

Memory (Third-
Party)

Context
Enhance

Context
Critic

0.91

0.64

0.86

0.71

0.43

0.58

0.75

0.85

0.87

0.85

0.77

0.64

COTとDPOの組み合わせ:

COT

DPO

Memory
(Self)

Memory
(Third-Party)

Context
Enhance

Context
Critic

12/16

St

Y

0 96

0 76

0 85

0 86

アプリケーション

SECOND MEの応用

情報過負荷と複雑な社会的インタラクションの時代において:

情報、感情、プロフェッショナルなアイデンティティの管理を支援

生産性、意思決定、認知管理を向上させる個人AI支援者として機能

需要側の観点から:

情報を効率的にフィルタリングして活用

仕事のパフォーマンスと意思決定を向上させるパーソナライズされた知
識を提供

内部的には:

13/16

アプリケーション

人間-AIネットワークの構築

人間-AIネットワーク: 接続は指数関数的に拡大し、メトカーフの法則を
強化

人間とAIノードの統合により、ネットワーク効率が3〜5桁向上

認知資本の変革:

個人の認知資産のためのNFTベースフレームワーク

数値化可能な「知識フロー効率」モデル

知識の普及と応用の強化

分散意思決定プロトコル:

14/16

結論と展望

結論、制限事項、展望

成果:

個人的な思考記録から始まり、自動化されたパイプラインに進化

モデル中心のアプローチによる多層ハイブリッドシステムの実現

SECOND MEとしての役割を果たすAIの能力測定と強化

課題:

初期の作業は単一ターンのトレーニングに依存

より深い合成が必要

モデルアライメントの精緻化にはより高度な技術が必要

実際のユーザーフィードバックが限られている

15/16

ご清聴ありがとうございました

SECOND ME: AI-native Memory 2.0

Jiale Wei, Xiang Ying, Tao Gao, Fangyi Bao, Felix Tao, Jingbo Shang

https://github.com/Mindverse/Second-Me

Mindverse.ai

16/16


